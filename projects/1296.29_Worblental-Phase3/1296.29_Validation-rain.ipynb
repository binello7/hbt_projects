{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import xarray as xr\n",
    "import yaml\n",
    "import warnings\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as td\n",
    "from itertools import cycle\n",
    "from pathlib import Path\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from matplotlib import colormaps\n",
    "from matplotlib.patches import Rectangle\n",
    "from hbt_tools import plots as hp\n",
    "from hbt_tools import utils_hbt as uh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ds(file_path):\n",
    "    with xr.open_dataset(file_path) as ds:\n",
    "        return ds\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def add_geo_features(ax):\n",
    "    \"\"\"\n",
    "    Add reference geographical layers such as thenational boundaries\n",
    "    and the main lakes and rivers.\n",
    "    \"\"\"\n",
    "    ax.add_feature(\n",
    "        cfeature.NaturalEarthFeature(\n",
    "            \"cultural\",\n",
    "            \"admin_0_boundary_lines_land\",\n",
    "            scale=\"10m\",\n",
    "            edgecolor=\"black\",\n",
    "            facecolor=\"none\",\n",
    "            linewidth=1,\n",
    "        )\n",
    "    )\n",
    "    ax.add_feature(\n",
    "        cfeature.NaturalEarthFeature(\n",
    "            \"physical\",\n",
    "            \"rivers_lake_centerlines\",\n",
    "            scale=\"10m\",\n",
    "            edgecolor=np.array([0.59375, 0.71484375, 0.8828125]),\n",
    "            facecolor=\"none\",\n",
    "            linewidth=1,\n",
    "        )\n",
    "    )\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def read_yaml(file_path):\n",
    "    with open(file_path) as f:\n",
    "        data_dict = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    \n",
    "    return data_dict\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def plot_precipfield(ds, save_path, figsize=(12, 7), fps=4):\n",
    "    epsg_lv03 = 21781\n",
    "    crs = ccrs.epsg(epsg_lv03)\n",
    "    dt_format = '%d.%m.%Y %H:%M'\n",
    "\n",
    "    # Plot settings\n",
    "    levels = np.logspace(-1, 2, 10, base=10)\n",
    "    cmap = \"Blues\"\n",
    "    fig = plt.figure(figsize=figsize);\n",
    "\n",
    "    precip_field = ds.RR.isel(time=0)\n",
    "    precip_field = precip_field.where(precip_field > 0)\n",
    "    dt0_str = ds.time.to_pandas().iloc[0].strftime(dt_format)\n",
    "\n",
    "    g = precip_field.plot(\n",
    "        transform=crs,\n",
    "        subplot_kws=dict(projection=crs),\n",
    "        levels=levels,\n",
    "        cmap=cmap\n",
    "        )\n",
    "    ax = g.axes\n",
    "    title = ax.title\n",
    "    add_geo_features(ax);\n",
    "\n",
    "    ax.add_patch(Rectangle((600000, 190000), 2e4, 2e4, edgecolor='red', fill=False));\n",
    "\n",
    "    # Animation\n",
    "    def animate(t):\n",
    "        data = ds.RR.isel(time=t)\n",
    "        time = ds.time.to_pandas().iloc[t] # time as Timestamp()\n",
    "        dt_str = time.strftime(dt_format)\n",
    "        data = data.where(data > 0).data.flatten()\n",
    "        g.set_array(data)\n",
    "        title.set_text(dt_str)\n",
    "        return (g, title) # must be given as tuple\n",
    "\n",
    "    def init():\n",
    "        data = precip_field.data.flatten()\n",
    "        g.set_array(data)\n",
    "        title.set_text(dt0_str)\n",
    "        return (g, title) # must be given as tuple\n",
    "\n",
    "    ani = FuncAnimation(fig, animate, range(len(ds.time)), init_func=init)\n",
    "    ani.save(save_path, writer=PillowWriter(fps=fps))\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def xarrays2ts(nc_list, dict_coords):\n",
    "    ts_list = []\n",
    "    for file in nc_list:\n",
    "        with xr.open_dataset(file) as ds:\n",
    "            ts =  pd.DataFrame(columns=['time', *dict_coords.keys()])\n",
    "            for k, v in dict_coords.items():\n",
    "                ts[k] = ds.sel(chx=v[0], chy=v[1], method='nearest').RR.data\n",
    "            \n",
    "            ts['time'] = ds.time.data\n",
    "            ts_list.append(ts)\n",
    "\n",
    "    ts_out = pd.concat(ts_list)\n",
    "    ts_out.set_index(keys='time', inplace=True)\n",
    "\n",
    "    ts_out = ts_out / 60 * 10 # Convert units: mm/h -> mm/10min\n",
    "    ts_out = ts_out.round(1)\n",
    "\n",
    "    return ts_out\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def ncs_to_ds(nc_list, slice_x, slice_y, dim='time'):\n",
    "    ds_list = []\n",
    "    for file in nc_list:\n",
    "        with xr.open_dataset(file) as ds:\n",
    "            ds = ds.sel(chx=slice_x, chy=slice_y, method=None)\n",
    "            ds_list.append(ds)\n",
    "\n",
    "    ds_out = xr.concat(ds_list, dim=dim)\n",
    "\n",
    "    return ds_out\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def obsname_from_date(date):\n",
    "    date = date.strftime('%Y%m')\n",
    "    obs_name = f\"radar-observations_{date}.nc\"\n",
    "\n",
    "    return obs_name\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def fcstname_from_date(date):\n",
    "    date = date.strftime('%Y%m%d%H%M')\n",
    "    fcst_name = f\"RR_INCA_{date}.nc\"\n",
    "\n",
    "    return fcst_name\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def ts_to_cumulativ(ts):\n",
    "    ts_out = ts.copy()\n",
    "    for name, col in ts_out.items():\n",
    "        ts_out[name] = col.cumsum()\n",
    "\n",
    "    return ts_out\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def convert_ds_units(ds, factor, variable, new_units):\n",
    "    ds = ds.copy(deep=True)\n",
    "    ds[variable] = ds[variable] * factor\n",
    "    ds[variable].attrs.update({'units': new_units})\n",
    "\n",
    "    return ds\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def compute_ds_diff(ds_obs, ds_fcst, variable, method='abs'):\n",
    "    '''\n",
    "    Computes the difference between forecast (fcst) and observations (obs).\n",
    "\n",
    "    The difference is computed as fcst - obs. This means, that positive values\n",
    "    indicate that forecast overestimates the reality, whereas negative values\n",
    "    indicate the opposite, that is forecast underestimates the reality.\n",
    "    '''\n",
    "    ds_obs = ds_obs.copy(deep=True)\n",
    "    ds_fcst = ds_fcst.copy(deep=True)\n",
    "\n",
    "    ds_obs = ds_obs[variable]\n",
    "    ds_fcst = ds_fcst[variable]\n",
    "\n",
    "    time_start = ds_fcst.time[0]\n",
    "    time_end = ds_fcst.time[-1]\n",
    "    time_slice = slice(time_start, time_end)\n",
    "\n",
    "    time_fcst = ds_fcst.time.sel(time=time_slice)\n",
    "    time_obs = ds_obs.time.sel(time=time_slice)\n",
    "\n",
    "    # BUG: diff(time_fcst/time_obs) != diff(time_obs/time_fcst)\n",
    "    if len(time_fcst > time_obs):\n",
    "        time_diff = set(time_fcst.to_numpy()).difference(set(time_obs.to_numpy()))\n",
    "    else:\n",
    "        time_diff = set(time_obs.to_numpy()).difference(set(time_fcst.to_numpy()))\n",
    "\n",
    "    if time_diff:\n",
    "        time_diff = list(time_diff) # cannot drop using set\n",
    "        warnings.warn(f\"The index 'time' for 'ds_obs' and 'ds_fcst' differs on \"\n",
    "            f\"the following elements: {time_diff}\")\n",
    "        time_fcst = time_fcst.drop_sel(time=time_diff)\n",
    "\n",
    "    ds_obs = ds_obs.sel(time=time_fcst)\n",
    "    ds_fcst = ds_fcst.sel(time=time_fcst)\n",
    "\n",
    "    if method == 'abs':\n",
    "        ds_out = ds_fcst - ds_obs\n",
    "\n",
    "    elif method == 'rel':\n",
    "        # ds_obs / ds_fcst is often 0 -> alternative: RPD - Relative Percent Difference\n",
    "        ds_out = 2 * (ds_fcst - ds_obs) / (abs(ds_obs) + abs(ds_fcst))\n",
    "        t_steps = len(ds_out.time)\n",
    "        for t in range(t_steps):\n",
    "            data = ds_out.isel(time=t).data\n",
    "            data[np.isnan(data)] = 0.0\n",
    "            ds_out.isel(time=t).data = data\n",
    "\n",
    "    return ds_out\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def xarray_to_gif(ds, save_path, variable=None, figsize=(7,7), levels=None, cmap=None, datum_format='%d.%m.%Y %H:%M', fps=4):\n",
    "    ds = ds.copy(deep=True)\n",
    "\n",
    "    epsg_lv03 = 21781\n",
    "    crs = ccrs.epsg(epsg_lv03)\n",
    "\n",
    "    # Plot settings\n",
    "    fig = plt.figure(figsize=figsize);\n",
    "\n",
    "    if variable:\n",
    "        ds = ds[variable]\n",
    "\n",
    "    if levels is None:\n",
    "        max_abs = abs(ds).max()\n",
    "        levels = np.linspace(-max_abs, max_abs, 21)\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = colormaps['RdBu']\n",
    "\n",
    "\n",
    "    raster_field = ds.isel(time=0)\n",
    "    datum0_str = ds.time.to_pandas().iloc[0].strftime(datum_format)\n",
    "\n",
    "    g = raster_field.plot(\n",
    "        transform=crs,\n",
    "        subplot_kws=dict(projection=crs),\n",
    "        levels=levels,\n",
    "        cmap=cmap,\n",
    "    )\n",
    "\n",
    "    ax = g.axes\n",
    "    title = ax.title\n",
    "\n",
    "    # Animation\n",
    "    def animate(t):\n",
    "        data = ds.isel(time=t)\n",
    "        time = ds.time.to_pandas().iloc[t] # time as Timestamp()\n",
    "        datum_str = time.strftime(datum_format)\n",
    "        g.set_array(data)\n",
    "        title.set_text(datum_str)\n",
    "\n",
    "        return (g, title) # must be given as tuple\n",
    "\n",
    "    def init():\n",
    "        data = raster_field.data.flatten()\n",
    "        g.set_array(data)\n",
    "        title.set_text(datum0_str)\n",
    "\n",
    "        return (g, title) # must be given as tuple\n",
    "\n",
    "    ani = FuncAnimation(fig, animate, range(len(ds.time)), init_func=init)\n",
    "    ani.save(save_path, writer=PillowWriter(fps=fps))\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def sum_per_timestep(ds, factor):\n",
    "    time = ds.time.data\n",
    "    res_list = []\n",
    "\n",
    "    for t in time:\n",
    "        ds_sel = ds.sel(time=t)\n",
    "        res = ds_sel.sum().data * factor\n",
    "        res = pd.DataFrame([[t, res]], columns=['time', 'value'])\n",
    "        res_list.append(res)\n",
    "\n",
    "    df_res = pd.concat(res_list)\n",
    "    df_res.set_index('time', inplace=True)\n",
    "\n",
    "    return df_res\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_radarobs = Path(r\"C:\\Users\\sru\\Downloads\\Radarbeobachtungen_Meteoschweiz\")\n",
    "dir_radarfcst = Path(r\"H:\\8 Archiv\\Radardaten_Meteoschweiz\")\n",
    "\n",
    "obs_list = list(dir_radarobs.glob('*.nc'))\n",
    "fcst_list = list(dir_radarfcst.glob('*.nc'))\n",
    "\n",
    "save_dir = Path(r\"H:\\2 Projekte\\1000-\\1200-\\1296\\1296.29 Integrale Bewirtschaftung Phase 3\\05 Berechnungen Grundlagen\"\n",
    "    r\"\\02 - Validierung Niederschlagsradardaten\\Plots\")\n",
    "\n",
    "yaml_events = Path(r\"H:\\2 Projekte\\1000-\\1200-\\1296\\1296.29 Integrale Bewirtschaftung Phase 3\"\n",
    "    r\"\\05 Berechnungen Grundlagen\\02 - Validierung Niederschlagsradardaten\\Regenereignisse.yaml\")\n",
    "yaml_stations = Path(r\"H:\\2 Projekte\\1000-\\1200-\\1296\\1296.29 Integrale Bewirtschaftung Phase 3\"\n",
    "    r\"\\05 Berechnungen Grundlagen\\02 - Validierung Niederschlagsradardaten\\stations.yaml\")\n",
    "\n",
    "start_date = '01.12.2022'\n",
    "end_date = '31.12.2023'\n",
    "date_format = '%d.%m.%Y %H:%M'\n",
    "\n",
    "mmh_mm10min = 10/60\n",
    "id_BER = 2561\n",
    "\n",
    "coord_BER = (601934.00, 204410.00)\n",
    "region_worblental = [\n",
    "    (600000, 210000),\n",
    "    (620000, 210000),\n",
    "    (620000, 190000),\n",
    "    (600000, 190000)\n",
    "]\n",
    "slice_x = slice(600000, 620000)\n",
    "slice_y = slice(190000, 210000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read yaml files\n",
    "events = read_yaml(yaml_events)\n",
    "stations = read_yaml(yaml_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data BER\n",
    "ts_BER = uh.mdb_getdata(id_BER, start_date, end_date, date_format='%d.%m.%Y')\n",
    "ts_BER.index = ts_BER.index.tz_convert('utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all obs\n",
    "ds_obs = ncs_to_ds(nc_list=obs_list, slice_x=slice_x, slice_y=slice_y)\n",
    "ds_obs = convert_ds_units(ds_obs, factor=mmh_mm10min, variable='RR', new_units='mm/10min')\n",
    "ds_obs = ds_obs.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ds_obs\n",
    "time_index = ds_obs.get_index(key='time')\n",
    "time_index\n",
    "\n",
    "# Check duplicated\n",
    "duplicates = time_index[time_index.duplicated()]\n",
    "duplicates\n",
    "\n",
    "# Remove duplicates\n",
    "ds_obs = ds_obs.drop_duplicates(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts_stations = xarrays2ts(obs_list, stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Bodenmessung / Radarmessung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_Zollikofen = pd.DataFrame(ts_stations.loc[:,'Zollikofen'])\n",
    "save_path = Path(r\"H:\\2 Projekte\\1000-\\1200-\\1296\\1296.29 Integrale Bewirtschaftung Phase 3\\05 Berechnungen Grundlagen\"\n",
    "    r\"\\03 - Regenereignisse\\Niederschlag_01_Ereignisdetektion\\Radarmessung_Zollikofen.csv\")\n",
    "ts_Zollikofen.to_csv(save_path, sep=';', date_format=date_format)\n",
    "\n",
    "save_path = save_dir / 'Vergleich_Boden-Radarmessung.html'\n",
    "lines = [\n",
    "    dict(color='blue'),\n",
    "    dict(color='red'),\n",
    "    dict(color='blue', dash='dash'),\n",
    "    dict(color='red', dash='dash')\n",
    "]\n",
    "fig = hp.ply_2y([ts_BER, ts_Zollikofen], [ts_BER.cumsum(), ts_Zollikofen.cumsum()],\n",
    "    names=['Bodenmessung BER', 'Radarmessung Zollikofen', 'Bodenmessung kumulativ', 'Radarmessung kumulativ'],\n",
    "    xlabel='Zeit', ylabels=['Regen [mm/10min]', 'Regen kumulativ [mm]'],\n",
    "    title='Vergleich Bodenmessung / Radarmessung', lines=lines, save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radarmessung: Comparison different Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations timeseries\n",
    "save_path = save_dir / 'Vergleich_TS_Stationen.html'\n",
    "fig = hp.ply_1y(ts_stations, names=ts_stations.columns, xlabel='Zeit', ylabel='Regen [mm/10min]',\n",
    "    title='Regenzeitreihen Stationen', save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations cumulative sum\n",
    "ts_stations_cum = ts_to_cumulativ(ts_stations)\n",
    "\n",
    "save_path = save_dir / 'Vergleich_TS-cum_Stationen.html'\n",
    "fig = hp.ply_1y(ts_stations_cum, names=ts_stations.columns, xlabel='Zeit', ylabel='Regen kumulativ [mm]',\n",
    "    title='Regensummen Stationen', save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison OBS - FCST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Schweiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = '%d.%m.%Y %H:%M'\n",
    "ts_events = {}\n",
    "\n",
    "for event, date in events.items():\n",
    "    out_dir = save_dir / event\n",
    "    if not out_dir.exists():\n",
    "        out_dir.mkdir()\n",
    "\n",
    "    start_date = dt.strptime(date, date_format)\n",
    "    end_date = start_date + td(hours=6)\n",
    "\n",
    "    yearmonth = start_date.strftime('%Y%m')\n",
    "    file_name = f'radar-observations_{yearmonth}.nc'\n",
    "    file_path = dir_radarobs / file_name\n",
    "\n",
    "    with xr.open_dataset(file_path) as ds:\n",
    "        ds = ds.sel(time=slice(start_date, end_date))\n",
    "\n",
    "    date_str = start_date.strftime('%y%m%d_%H%M')\n",
    "    save_path = out_dir / f'Schweiz_{date_str}.gif'\n",
    "    plot_precipfield(ds, save_path);\n",
    "\n",
    "\n",
    "    file_name = fcstname_from_date(start_date)\n",
    "    file_path = dir_radarfcst / file_name\n",
    "\n",
    "    if file_path.exists():\n",
    "        with xr.open_dataset(file_path) as ds_fcst:\n",
    "            ts_fcst =  pd.DataFrame(columns=['time', *stations.keys()])\n",
    "            for name, coords in stations.items():\n",
    "                ts_fcst[name] = ds_fcst.sel(chx=coords[0], chy=coords[1], method='nearest').RR.data\n",
    "\n",
    "            ts_fcst['time'] = ds_fcst.time.data\n",
    "            ts_fcst.set_index('time', inplace=True)\n",
    "            ts_fcst = ts_fcst / 60 * 10 # Convert units: mm/h -> mm/10min\n",
    "            ts_fcst = ts_fcst.round(1)\n",
    "            ts_fcst.columns = [f\"FCST {x}\" for x in ts_fcst.columns]\n",
    "        \n",
    "            save_path = out_dir / f'FCST-Stations_{date_str}.csv'\n",
    "            ts_fcst.to_csv(save_path, sep=';')\n",
    "\n",
    "            ts_events.update({event: ts_fcst})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Worblental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event, date in events.items():\n",
    "    start_date = dt.strptime(date, date_format)\n",
    "    end_date = start_date + td(hours=6)\n",
    "\n",
    "    ds = ds_obs.sel(time=slice(start_date, end_date))\n",
    "\n",
    "    save_path = save_dir / event /  f\"Worblental_{start_date.strftime('%y%m%d_%H%M')}.gif\"\n",
    "    plot_precipfield(ds, save_path, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Stations Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cycle(px.colors.qualitative.Plotly)\n",
    "for event, ts_fcst in ts_events.items():\n",
    "    start_date = ts_fcst.index[0]\n",
    "    end_date = ts_fcst.index[-1]\n",
    "\n",
    "    ts_obs = ts_stations.loc[start_date:end_date]\n",
    "    ts_obs.columns = [f\"OBS {x}\" for x in ts_obs.columns]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for i in range(ts_obs.shape[1]):\n",
    "        color = next(colors)\n",
    "        fig.add_trace(go.Scatter(x=ts_obs.index, y=ts_obs.iloc[:,i], name=ts_obs.columns[i], line=dict(color=color)))\n",
    "        fig.add_trace(go.Scatter(x=ts_fcst.index, y=ts_fcst.iloc[:,i], name=ts_fcst.columns[i], line=dict(dash='dash', color=color)))\n",
    "\n",
    "        fig.update_xaxes(title='Zeit')\n",
    "        fig.update_yaxes(title=\"Regen [mm/10min]\")\n",
    "        fig.update_layout(title=event)\n",
    "\n",
    "        save_path = save_dir / event / 'Comparison_obs_fcst.html'\n",
    "        fig.write_html(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Stations Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event, ts_fcst in ts_events.items():\n",
    "    ts_fcst = ts_to_cumulativ(ts_fcst)\n",
    "\n",
    "    start_date = ts_fcst.index[0]\n",
    "    end_date = ts_fcst.index[-1]\n",
    "\n",
    "    ts_obs = ts_stations.loc[start_date:end_date]\n",
    "    ts_obs = ts_to_cumulativ(ts_obs)\n",
    "    ts_obs.columns = [f\"OBS {x}\" for x in ts_obs.columns]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for i in range(ts_obs.shape[1]):\n",
    "        color = next(colors)\n",
    "        fig.add_trace(go.Scatter(x=ts_obs.index, y=ts_obs.iloc[:,i], name=ts_obs.columns[i], line=dict(color=color)))\n",
    "        fig.add_trace(go.Scatter(x=ts_fcst.index, y=ts_fcst.iloc[:,i], name=ts_fcst.columns[i], line=dict(dash='dash', color=color)))\n",
    "\n",
    "        fig.update_xaxes(title='Zeit')\n",
    "        fig.update_yaxes(title=\"Regen kumulativ\")\n",
    "        fig.update_layout(title=f\"{event} - Regensumme\")\n",
    "\n",
    "        save_path = save_dir / event / 'Comparison_obs-fcst_cum.html'\n",
    "        fig.write_html(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(0.0, 370.0, 10)\n",
    "ts_diff_all = pd.DataFrame(index=index)\n",
    "ts_diff_all.index.set_names('lead-time [min]', inplace=True)\n",
    "\n",
    "for event, date in events.items():\n",
    "    print(event)\n",
    "    start_date = dt.strptime(date, date_format)\n",
    "    end_date = start_date + td(hours=6)\n",
    "\n",
    "    file_name = fcstname_from_date(start_date)\n",
    "    file_path = dir_radarfcst / file_name\n",
    "\n",
    "    ds_fcst = open_ds(file_path)\n",
    "    ds_fcst = ds_fcst.sel(chx=slice_x, chy=slice_y)\n",
    "    ds_fcst = convert_ds_units(ds_fcst, factor=mmh_mm10min, variable='RR', new_units='mm/10min')\n",
    "    ds_fcst = ds_fcst.round(1)\n",
    "\n",
    "    # Compute / plot ds_diff\n",
    "    ds_diff = compute_ds_diff(ds_obs, ds_fcst, variable='RR')\n",
    "    ds_diff.name = 'Regendifferenz [mm/10min]'\n",
    "    save_path = save_dir / event / f\"diff_{start_date.strftime('%y%m%d_%H')}.gif\"\n",
    "    levels = np.linspace(-4, 4, 21)\n",
    "    cmap = xarray_to_gif(ds_diff, save_path=save_path, fps=1, levels=levels)\n",
    "\n",
    "    # Compute / plot ds_diff_abs\n",
    "    ds_diff_abs = abs(ds_diff)\n",
    "    ds_diff_abs.name = 'Regendifferenz absolut [mm/10min]'\n",
    "    save_path = save_dir / event / f\"diff_abs_{start_date.strftime('%y%m%d_%H')}.gif\"\n",
    "    levels = np.linspace(0, 4, 21)\n",
    "    xarray_to_gif(ds_diff_abs, save_path=save_path, fps=1, cmap='Reds', levels=levels)\n",
    "\n",
    "    # Compute / plot ds_diff_rel\n",
    "    ds_diff_rel = compute_ds_diff(ds_obs, ds_fcst, variable='RR', method='rel')\n",
    "    ds_diff_rel = ds_diff_rel * 100\n",
    "    ds_diff_rel.name = 'Regendifferenz prozent [%]'\n",
    "    save_path = save_dir / event / f\"diff_rel_{start_date.strftime('%y%m%d_%H')}.gif\"\n",
    "    # levels = np.linspace(-1, 1, 21)\n",
    "    xarray_to_gif(ds_diff_rel, save_path=save_path, fps=1)\n",
    "\n",
    "\n",
    "    # Compute timeseries (ts)\n",
    "    ## diff\n",
    "    ts_diff = sum_per_timestep(ds_diff, factor=1/(20**2))\n",
    "    ts_diff_cum = ts_diff.cumsum()\n",
    "    save_path = save_dir / event / 'ts_-diff.html'\n",
    "    fig = hp.ply_1y([ts_diff, ts_diff_cum], xlabel='Zeit', ylabel='Regendifferenz [mm]', \n",
    "        title=f\"Differenz: {event} - {date}\", names=['Differenz pro Zeitschritt', 'Differenz kumulativ']);\n",
    "    fig.update_layout(font=dict(size=25))\n",
    "    fig.write_html(save_path)\n",
    "\n",
    "    ## diff_abs\n",
    "    ts_diff_abs = sum_per_timestep(ds_diff_abs, factor=1/(20**2))\n",
    "    ts_diff_abs_cum = ts_diff_abs.cumsum()\n",
    "    save_path = save_dir / event / 'ts_abs-diff.html'\n",
    "    fig = hp.ply_1y([ts_diff_abs, ts_diff_abs_cum], save_path=save_path, xlabel='Zeit', ylabel='Regendifferenz [mm]',\n",
    "        title=f\"Absolute Differenz: {event} - {date}\", names=['Differenz pro Zeitschritt', 'Differenz kumulativ']);\n",
    "    fig.update_layout(font=dict(size=25))\n",
    "    fig.write_html(save_path)\n",
    "\n",
    "    # Update ts_diff_all\n",
    "    time_0 = ts_diff.index[0]\n",
    "    lead_time = ts_diff.index - time_0\n",
    "    lead_time = lead_time.total_seconds() / 60\n",
    "    ts_leadtime = pd.DataFrame(index=lead_time, data=ts_diff.iloc[:,0].cumsum().to_list())\n",
    "    ts_diff_all[event] = ts_leadtime\n",
    "    ts_diff_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Std over all Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff_all['mean'] = ts_diff_all.mean(axis='columns')\n",
    "ts_diff_all['std'] = ts_diff_all.std(axis='columns')\n",
    "ts_diff_all['pos-std'] = ts_diff_all[ts_diff_all>=0].std(axis='columns')\n",
    "ts_diff_all['neg-std'] = ts_diff_all[ts_diff_all<=0].std(axis='columns')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(x=ts_diff_all.index, y=ts_diff_all['mean'], yerr=[ts_diff_all['neg-std'], ts_diff_all['pos-std']],\n",
    "    ecolor='red', fmt='b-x')\n",
    "plt.xlabel('Vorlaufzeit [min]')\n",
    "plt.ylabel('Differenz [mm]')\n",
    "plt.grid(True, linestyle='--', color='grey')\n",
    "\n",
    "ax.legend(['Mtl. kumul. Regendifferenz'])\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = save_dir / 'Regendiff_avg-cumul.png'\n",
    "fig.savefig(save_path, dpi=600)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sup_inf = pd.DataFrame(ts_diff_all.iloc[:,12])\n",
    "ts_sup_inf['lim-sup'] = ts_diff_all.iloc[:,12] + ts_diff_all.iloc[:,14]\n",
    "ts_sup_inf['lim-inf'] = ts_diff_all.iloc[:,12] - ts_diff_all.iloc[:,15]\n",
    "\n",
    "save_path = save_dir / 'sup-inf_data_mm.csv'\n",
    "ts_sup_inf.astype(float).to_csv(save_path, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
